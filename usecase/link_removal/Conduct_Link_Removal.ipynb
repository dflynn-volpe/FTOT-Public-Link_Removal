{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential removal of links and resiliency testing\n",
    "\n",
    "- Disruption of a network by removal of links, based on:\n",
    "    + Sum of betweeness centrality of from and to nodes\n",
    "    + Link length\n",
    "    + Volume of commodity flow\n",
    "- Calculation of performance in terms of cost and unmet demand by re-running disrupted network on FOT\n",
    "- Plot link removal along x-axis and performance on y-axis, comparing networks of differing evenness. Dynamic report generated in an Rmarkdown automatically from this Notebook.\n",
    "\n",
    "**Assumptions**\n",
    "\n",
    "- Working in a Python 3.x environment for this notebook\n",
    "    + Refer to the README in this repository for instructions on setup of all dependencies with `conda`\n",
    "- Python 2.7 installed as part of ArcGIS\n",
    "- 64 bit background geoprocessing enabled\n",
    "- Access to ArcGIS license server if necessary \n",
    "\n",
    "*Reference*\n",
    "\n",
    "- [NetworkX Documentation](https://networkx.github.io/documentation/stable/tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sqlalchemy \n",
    "import networkx as nx\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import resiliency_disruptions\n",
    "\n",
    "# Uses Quick Start 7 as an example. Modify `scen_name` and `scen_path` for your scenario.\n",
    "scen_name = 'qs7_rmp_proc_dest_multi_inputs\\\\Default'\n",
    "\n",
    "scen_path = os.path.join(\"C:\\\\FTOT\\\\scenarios\\\\quick_start\\\\\", scen_name)\n",
    "\n",
    "shp_path = os.path.join(scen_path, 'temp_networkx_shp_files')\n",
    "\n",
    "picklename = os.path.join(scen_path, 'BetweenessG.pickle')\n",
    "\n",
    "if not os.path.exists(shp_path):\n",
    "    print('Please modify the FTOT code using the `ftot_networkx.py` and `ftot_routing.py` scripts in this repository and run the scenario again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in prepared betweeness centrality and road network graph data. \n",
    "# If these don't exist, the following steps will create them\n",
    "if os.path.exists(picklename):\n",
    "    file = open(picklename, 'rb')\n",
    "    betweenness_dict_road = pickle.load(file)\n",
    "    G_road = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by using betweeness centrality calculation using networkX\n",
    "if not os.path.exists(picklename):\n",
    "    G_road = nx.read_shp(os.path.join(shp_path, 'road.shp'), simplify=True)\n",
    "    G_road = nx.convert_node_labels_to_integers(G_road, first_label=0, ordering='default', label_attribute=\"xy_coord_label\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run betweenness centrality on the NetworkX graph\n",
    "# Note: This step might take 20+ minutes\n",
    "# Run if pickle not available\n",
    "if not os.path.exists(picklename):\n",
    "    print('Running Betweeness Centrality calculations. This might take more than 20 minutes.')\n",
    "    betweenness_dict_road = nx.betweenness_centrality(G_road, normalized=False, weight='MILES')\n",
    "    print('Completed Betweeness Centrality calculations.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with pickle\n",
    "# On load, need to know that there are two objects in this pickle, the betweeness centrality dict and the network G\n",
    "if not os.path.exists(picklename):\n",
    "    with open(picklename, 'wb') as handle:\n",
    "        pickle.dump(betweenness_dict_road, handle)\n",
    "        pickle.dump(G_road, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Betweeness Centrality calculations to edges \n",
    "\n",
    "- Sum BC for each node of a link\n",
    "- Create data frame for repeated link removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\FTOT\\scenarios\\quick_start\\qs7_rmp_proc_dest_multi_inputs\\Default\n"
     ]
    }
   ],
   "source": [
    "# Read in FTOT data\n",
    "print(scen_path)\n",
    "db_name = 'main.db'\n",
    "\n",
    "db_path = 'sqlite:///' + os.path.join(scen_path, db_name)\n",
    "\n",
    "engine = sqlalchemy.create_engine(db_path)\n",
    "\n",
    "table_name = 'networkx_edges'\n",
    "nx_edges = pd.read_sql_table(table_name, engine)\n",
    "\n",
    "table_name = 'networkx_nodes'\n",
    "nx_nodes = pd.read_sql_table(table_name, engine)\n",
    "\n",
    "table_name = 'optimal_variables'\n",
    "optimal_vars = pd.read_sql_table(table_name, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DANIEL~1.FLY\\AppData\\Local\\Temp/ipykernel_16580/1918546944.py:1: DeprecationWarning: read_shp is deprecated and will be removed in 3.0.See https://networkx.org/documentation/latest/auto_examples/index.html#geospatial.\n",
      "  G_road_orig_label = nx.read_shp(os.path.join(shp_path, 'road.shp'), simplify=True)\n"
     ]
    }
   ],
   "source": [
    "G_road_orig_label = nx.read_shp(os.path.join(shp_path, 'road.shp'), simplify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_orig_label_nodes = list(G_road_orig_label.nodes) # these values are the shape_x and shape_y values in `networkx_nodes`. \n",
    "# Use that to get node_id from networkx_edges in the database,\n",
    "# Then use those id values to get edges info\n",
    "# Then line up the new integer labels with this list of ids to get betweeness centrality for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the betweeness_centrality values as the framework to join in shape_x, shape_y, and node_id\n",
    "bc_df_road = pd.DataFrame.from_dict(betweenness_dict_road, orient = 'index')\n",
    "bc_df_road = bc_df_road.rename(columns = {0: 'BC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_shape_df_road = pd.DataFrame(road_orig_label_nodes)\n",
    "\n",
    "bc_shape_df_road = pd.concat([bc_df_road, node_shape_df_road], axis = 1)\n",
    "bc_shape_df_road = bc_shape_df_road.rename(columns = {0: 'shape_x', 1: 'shape_y'})\n",
    "\n",
    "# Now add node_id from networkx_nodes, using pandas merge with left join.\n",
    "# Use both shape_x and shape_y to identify the nodes correctly\n",
    "# Union of both prod and crude now\n",
    "\n",
    "bc_node_df = pd.merge(bc_shape_df_road, nx_nodes, on = ['shape_x', 'shape_y'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use this data frame to populate a data frame of edges. \n",
    "# We will want the following from networkx_edges:\n",
    "# edge_id, from_node_id, to_node_id, mode_source, miles, mode_source_oid, \n",
    "# Then using the node_id column in the new bc_node_df, add these:\n",
    "# from_node_BC, to_node_BC\n",
    "# and sum those for sum_node_BC\n",
    "merge_from = pd.merge(nx_edges, bc_node_df[['BC','node_id']],\n",
    "                      left_on = 'from_node_id',\n",
    "                      right_on = 'node_id',\n",
    "                      how = 'left')\n",
    "merge_from = merge_from.rename(columns = {'BC': 'from_node_BC'})\n",
    "\n",
    "merge_to = pd.merge(merge_from, bc_node_df[['BC','node_id',]],\n",
    "                    left_on = 'to_node_id',\n",
    "                    right_on = 'node_id',\n",
    "                    how = 'left')\n",
    "merge_to = merge_to.rename(columns = {'BC': 'to_node_BC'})\n",
    "\n",
    "# Sum the BC values\n",
    "\n",
    "merge_to['sum_BC'] = merge_to.filter(like = \"node_BC\").sum(axis = 1)\n",
    "\n",
    "# Then from optimal_variables, get variable_name, nc_edge_id, mode, mode_oid, miles,\n",
    "# variable_value, converted_capacity, and converted_volume\n",
    "\n",
    "use_opt_vars = ['variable_type',\n",
    "               'var_id',\n",
    "               'variable_value',\n",
    "                'variable_name',\n",
    "                'nx_edge_id',\n",
    "                'mode_oid',\n",
    "                'converted_capacity',\n",
    "                'converted_volume'\n",
    "               ]\n",
    "\n",
    "merge_opt = pd.merge(merge_to, optimal_vars[use_opt_vars],\n",
    "                    left_on = 'edge_id',\n",
    "                    right_on = 'nx_edge_id',\n",
    "                    how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edge_id</th>\n",
       "      <th>from_node_id</th>\n",
       "      <th>to_node_id</th>\n",
       "      <th>artificial</th>\n",
       "      <th>mode_source</th>\n",
       "      <th>mode_source_oid</th>\n",
       "      <th>miles</th>\n",
       "      <th>route_cost_scaling</th>\n",
       "      <th>capacity</th>\n",
       "      <th>volume</th>\n",
       "      <th>...</th>\n",
       "      <th>node_id_y</th>\n",
       "      <th>sum_BC</th>\n",
       "      <th>variable_type</th>\n",
       "      <th>var_id</th>\n",
       "      <th>variable_value</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>nx_edge_id</th>\n",
       "      <th>mode_oid</th>\n",
       "      <th>converted_capacity</th>\n",
       "      <th>converted_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2222</td>\n",
       "      <td>2</td>\n",
       "      <td>rail</td>\n",
       "      <td>206</td>\n",
       "      <td>0.013221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>42181</td>\n",
       "      <td>2</td>\n",
       "      <td>water</td>\n",
       "      <td>5081</td>\n",
       "      <td>0.351856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2223</td>\n",
       "      <td>2</td>\n",
       "      <td>rail</td>\n",
       "      <td>207</td>\n",
       "      <td>0.064799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   edge_id  from_node_id  to_node_id  artificial mode_source  mode_source_oid  \\\n",
       "0        1             0        2222           2        rail              206   \n",
       "1        2             0       42181           2       water             5081   \n",
       "2        3             1        2223           2        rail              207   \n",
       "\n",
       "      miles  route_cost_scaling  capacity  volume  ...  node_id_y  sum_BC  \\\n",
       "0  0.013221                 1.0       NaN     0.0  ...        NaN     0.0   \n",
       "1  0.351856                 1.0       NaN     NaN  ...        NaN     0.0   \n",
       "2  0.064799                 1.0       NaN     0.0  ...        NaN     0.0   \n",
       "\n",
       "   variable_type  var_id  variable_value  variable_name nx_edge_id  mode_oid  \\\n",
       "0            NaN     NaN             NaN            NaN        NaN       NaN   \n",
       "1            NaN     NaN             NaN            NaN        NaN       NaN   \n",
       "2            NaN     NaN             NaN            NaN        NaN       NaN   \n",
       "\n",
       "   converted_capacity converted_volume  \n",
       "0                 NaN              NaN  \n",
       "1                 NaN              NaN  \n",
       "2                 NaN              NaN  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_opt.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>edge_id</th>\n",
       "      <th>from_node_id</th>\n",
       "      <th>to_node_id</th>\n",
       "      <th>miles</th>\n",
       "      <th>capacity</th>\n",
       "      <th>volume</th>\n",
       "      <th>sum_BC</th>\n",
       "      <th>variable_type</th>\n",
       "      <th>variable_value</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>nx_edge_id</th>\n",
       "      <th>mode_oid</th>\n",
       "      <th>converted_capacity</th>\n",
       "      <th>converted_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52651</td>\n",
       "      <td>52652</td>\n",
       "      <td>23240</td>\n",
       "      <td>22927</td>\n",
       "      <td>2.391027</td>\n",
       "      <td>45396.405255</td>\n",
       "      <td>44631.0</td>\n",
       "      <td>12291580.0</td>\n",
       "      <td>Edge</td>\n",
       "      <td>90.718474</td>\n",
       "      <td>Edge_157928</td>\n",
       "      <td>52652.0</td>\n",
       "      <td>12925.0</td>\n",
       "      <td>1.089514e+06</td>\n",
       "      <td>1071144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51780</td>\n",
       "      <td>51781</td>\n",
       "      <td>22901</td>\n",
       "      <td>23033</td>\n",
       "      <td>3.527136</td>\n",
       "      <td>52814.692258</td>\n",
       "      <td>52543.0</td>\n",
       "      <td>10650212.0</td>\n",
       "      <td>Edge</td>\n",
       "      <td>90.718474</td>\n",
       "      <td>Edge_155315</td>\n",
       "      <td>51781.0</td>\n",
       "      <td>12949.0</td>\n",
       "      <td>1.267553e+06</td>\n",
       "      <td>1261032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51839</td>\n",
       "      <td>51840</td>\n",
       "      <td>22927</td>\n",
       "      <td>22928</td>\n",
       "      <td>1.124715</td>\n",
       "      <td>50570.979389</td>\n",
       "      <td>46904.0</td>\n",
       "      <td>10300608.0</td>\n",
       "      <td>Edge</td>\n",
       "      <td>90.718474</td>\n",
       "      <td>Edge_155492</td>\n",
       "      <td>51840.0</td>\n",
       "      <td>12525.0</td>\n",
       "      <td>1.213704e+06</td>\n",
       "      <td>1125696.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  edge_id  from_node_id  to_node_id     miles      capacity   volume  \\\n",
       "0  52651    52652         23240       22927  2.391027  45396.405255  44631.0   \n",
       "1  51780    51781         22901       23033  3.527136  52814.692258  52543.0   \n",
       "2  51839    51840         22927       22928  1.124715  50570.979389  46904.0   \n",
       "\n",
       "       sum_BC variable_type  variable_value variable_name  nx_edge_id  \\\n",
       "0  12291580.0          Edge       90.718474   Edge_157928     52652.0   \n",
       "1  10650212.0          Edge       90.718474   Edge_155315     51781.0   \n",
       "2  10300608.0          Edge       90.718474   Edge_155492     51840.0   \n",
       "\n",
       "   mode_oid  converted_capacity  converted_volume  \n",
       "0   12925.0        1.089514e+06         1071144.0  \n",
       "1   12949.0        1.267553e+06         1261032.0  \n",
       "2   12525.0        1.213704e+06         1125696.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create ranked lists of edges to remove.\n",
    "# First, keep only edges in the optimal solution.\n",
    "# Then rank by sum_BC. Then just keep the columns we need, and reset the index.\n",
    "use_cols = ['edge_id', 'from_node_id', 'to_node_id', 'miles', 'capacity', 'volume', 'sum_BC',\n",
    "           'variable_type', 'variable_value', 'variable_name', 'nx_edge_id', 'mode_oid', 'converted_capacity', 'converted_volume']\n",
    "\n",
    "edges_remove = merge_opt[merge_opt['variable_value'] > 0].sort_values(by = 'sum_BC', ascending = False).filter(items = use_cols).reset_index()\n",
    "\n",
    "edges_remove.to_csv(os.path.join(scen_path, 'Edges_to_Remove.csv'),\n",
    "                   index = False)\n",
    "\n",
    "edges_remove.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Scenarios, Disrupt, Run FTOT\n",
    "\n",
    "Create disrupted network by copying everyhing in `scen_path` to a new directory\n",
    "\n",
    "Then overwrites the `networkx_edges` tables in that main.db, with the disrupted versions.\n",
    "\n",
    "##### Assuptions:\n",
    "\n",
    "  1. ArcGIS with 64-bit geoprocessing is installed\n",
    "  2. The FTOT version being used has been modified according to the `README` in this directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 25 scenarios based on Default\n"
     ]
    }
   ],
   "source": [
    "disrupt_type = 'BC' # Can disrupt basaed on betweeness centrality or volume, 'V'\n",
    "disrupt_steps = 25  # This is the number of steps to use. Recommend at least 25.\n",
    "\n",
    "resiliency_disruptions.make_disruption_scenarios(disrupt_type, disrupt_steps, scen_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disrupted 25 scenarios\n"
     ]
    }
   ],
   "source": [
    "resiliency_disruptions.disrupt_network(disrupt_type, disrupt_steps, scen_path, edges_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\FTOT\\program\\ftot.py\n"
     ]
    }
   ],
   "source": [
    "PYTHON = r\"C:\\FTOT\\python3_env\\python.exe\"\n",
    "repo_location = %pwd\n",
    "repo_location = os.path.split(repo_location)[0] \n",
    "FTOT = r\"C:\\FTOT\\program\\ftot.py\" # Optionally: os.path.join(repo_location, 'program', 'ftot.py')\n",
    "print(FTOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running o1 for disrupt01\n",
      "Running o2 for disrupt01\n",
      "Running p for disrupt01\n",
      "Running d for disrupt01\n",
      "Preparing to search over o2_log_2022_03_15_19-58-38.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           01            0          0   263      3,643\n",
      "Running o1 for disrupt02\n",
      "Running o2 for disrupt02\n",
      "Running p for disrupt02\n",
      "Running d for disrupt02\n",
      "Preparing to search over o2_log_2022_03_15_20-02-33.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           02            0          0   263      3,643\n",
      "Running o1 for disrupt03\n",
      "Running o2 for disrupt03\n",
      "Running p for disrupt03\n",
      "Running d for disrupt03\n",
      "Preparing to search over o2_log_2022_03_15_20-04-33.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           03            0          0   263      3,643\n",
      "Running o1 for disrupt04\n",
      "Running o2 for disrupt04\n",
      "Running p for disrupt04\n",
      "Running d for disrupt04\n",
      "Preparing to search over o2_log_2022_03_15_20-06-32.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           04            0          0   263      3,643\n",
      "Running o1 for disrupt05\n",
      "Running o2 for disrupt05\n",
      "Running p for disrupt05\n",
      "Running d for disrupt05\n",
      "Preparing to search over o2_log_2022_03_15_20-08-31.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           05            0          0   263      3,643\n",
      "Running o1 for disrupt06\n",
      "Running o2 for disrupt06\n",
      "Running p for disrupt06\n",
      "Running d for disrupt06\n",
      "Preparing to search over o2_log_2022_03_15_20-10-30.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           06            0          0   263      3,643\n",
      "Running o1 for disrupt07\n",
      "Running o2 for disrupt07\n",
      "Running p for disrupt07\n",
      "Running d for disrupt07\n",
      "Preparing to search over o2_log_2022_03_15_20-12-28.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           07            0          0   214      3,657\n",
      "Running o1 for disrupt08\n",
      "Running o2 for disrupt08\n",
      "Running p for disrupt08\n",
      "Running d for disrupt08\n",
      "Preparing to search over o2_log_2022_03_15_20-14-26.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           08            0          0   214      3,657\n",
      "Running o1 for disrupt09\n",
      "Running o2 for disrupt09\n",
      "Running p for disrupt09\n",
      "Running d for disrupt09\n",
      "Preparing to search over o2_log_2022_03_15_20-16-25.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           09            0          0   214      3,657\n",
      "Running o1 for disrupt10\n",
      "Running o2 for disrupt10\n",
      "Running p for disrupt10\n",
      "Running d for disrupt10\n",
      "Preparing to search over o2_log_2022_03_15_20-18-24.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           10            0          0   214      3,657\n",
      "Running o1 for disrupt11\n",
      "Running o2 for disrupt11\n",
      "Running p for disrupt11\n",
      "Running d for disrupt11\n",
      "Preparing to search over o2_log_2022_03_15_20-20-22.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           11            0          0   214      3,657\n",
      "Running o1 for disrupt12\n",
      "Running o2 for disrupt12\n",
      "Running p for disrupt12\n",
      "Running d for disrupt12\n",
      "Preparing to search over o2_log_2022_03_15_20-22-21.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           12            0          0   214      3,657\n",
      "Running o1 for disrupt13\n",
      "Running o2 for disrupt13\n",
      "Running p for disrupt13\n",
      "Running d for disrupt13\n",
      "Preparing to search over o2_log_2022_03_15_20-24-18.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           13            0          0   214      3,657\n",
      "Running o1 for disrupt14\n",
      "Running o2 for disrupt14\n",
      "Running p for disrupt14\n",
      "Running d for disrupt14\n",
      "Preparing to search over o2_log_2022_03_15_20-26-16.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           14            0          0   214      3,657\n",
      "Running o1 for disrupt15\n",
      "Running o2 for disrupt15\n",
      "Running p for disrupt15\n",
      "Running d for disrupt15\n",
      "Preparing to search over o2_log_2022_03_15_20-28-13.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           15            0          0   214      3,657\n",
      "Running o1 for disrupt16\n",
      "Running o2 for disrupt16\n",
      "Running p for disrupt16\n",
      "Running d for disrupt16\n",
      "Preparing to search over o2_log_2022_03_15_20-30-12.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           16            0          0   214      3,657\n",
      "Running o1 for disrupt17\n",
      "Running o2 for disrupt17\n",
      "Running p for disrupt17\n",
      "Running d for disrupt17\n",
      "Preparing to search over o2_log_2022_03_15_20-32-12.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           17            0          0   214      3,657\n",
      "Running o1 for disrupt18\n",
      "Running o2 for disrupt18\n",
      "Running p for disrupt18\n",
      "Running d for disrupt18\n",
      "Preparing to search over o2_log_2022_03_15_20-34-12.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           18            0          0   214      3,659\n",
      "Running o1 for disrupt19\n",
      "Running o2 for disrupt19\n",
      "Running p for disrupt19\n",
      "Running d for disrupt19\n",
      "Preparing to search over o2_log_2022_03_15_20-36-10.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           19            0          0   214      3,659\n",
      "Running o1 for disrupt20\n",
      "Running o2 for disrupt20\n",
      "Running p for disrupt20\n",
      "Running d for disrupt20\n",
      "Preparing to search over o2_log_2022_03_15_20-38-15.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           20            0          0   214      3,659\n",
      "Running o1 for disrupt21\n",
      "Running o2 for disrupt21\n",
      "Running p for disrupt21\n",
      "Running d for disrupt21\n",
      "Preparing to search over o2_log_2022_03_15_20-40-15.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           21            0          0   214      3,659\n",
      "Running o1 for disrupt22\n",
      "Running o2 for disrupt22\n",
      "Running p for disrupt22\n",
      "Running d for disrupt22\n",
      "Preparing to search over o2_log_2022_03_15_20-42-15.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           22            0          0   214      3,659\n",
      "Running o1 for disrupt23\n",
      "Running o2 for disrupt23\n",
      "Running p for disrupt23\n",
      "Running d for disrupt23\n",
      "Preparing to search over o2_log_2022_03_15_20-44-14.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           23            0          0   217      3,660\n",
      "Running o1 for disrupt24\n",
      "Running o2 for disrupt24\n",
      "Running p for disrupt24\n",
      "Running d for disrupt24\n",
      "Preparing to search over o2_log_2022_03_15_20-46-14.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           24            0          0   217      3,660\n",
      "Running o1 for disrupt25\n",
      "Running o2 for disrupt25\n",
      "Running p for disrupt25\n",
      "Running d for disrupt25\n",
      "Preparing to search over o2_log_2022_03_15_20-48-13.log\n",
      "  disrupt_step unmet_demand unmet_cost nedge total_cost\n",
      "0           25            0          0   228      3,895\n"
     ]
    }
   ],
   "source": [
    "# Begin running O steps of FTOT on the disupted scenarios\n",
    "# This may take several hours, depending on size of the network and number of steps\n",
    "\n",
    "results = resiliency_disruptions.run_o_steps(disrupt_type, disrupt_steps, scen_path, PYTHON, FTOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>disrupt_step</th>\n",
       "      <th>unmet_demand</th>\n",
       "      <th>unmet_cost</th>\n",
       "      <th>nedge</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>3,643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>3,643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>3,643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>3,643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>3,643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>3,643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>3,659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>3,660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>3,660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>3,895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index disrupt_step unmet_demand unmet_cost nedge total_cost\n",
       "0       0           01            0          0   263      3,643\n",
       "1       0           02            0          0   263      3,643\n",
       "2       0           03            0          0   263      3,643\n",
       "3       0           04            0          0   263      3,643\n",
       "4       0           05            0          0   263      3,643\n",
       "5       0           06            0          0   263      3,643\n",
       "6       0           07            0          0   214      3,657\n",
       "7       0           08            0          0   214      3,657\n",
       "8       0           09            0          0   214      3,657\n",
       "9       0           10            0          0   214      3,657\n",
       "10      0           11            0          0   214      3,657\n",
       "11      0           12            0          0   214      3,657\n",
       "12      0           13            0          0   214      3,657\n",
       "13      0           14            0          0   214      3,657\n",
       "14      0           15            0          0   214      3,657\n",
       "15      0           16            0          0   214      3,657\n",
       "16      0           17            0          0   214      3,657\n",
       "17      0           18            0          0   214      3,659\n",
       "18      0           19            0          0   214      3,659\n",
       "19      0           20            0          0   214      3,659\n",
       "20      0           21            0          0   214      3,659\n",
       "21      0           22            0          0   214      3,659\n",
       "22      0           23            0          0   217      3,660\n",
       "23      0           24            0          0   217      3,660\n",
       "24      0           25            0          0   228      3,895"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Repeat with volume-based disruptions\n",
    "\n",
    "Creates a separate directory tree for the volume-based disruptions, and carries out the disruption steps on that set.\n",
    "\n",
    "Set the variable `DO_VOLUME` to `True` to run the following steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_VOLUME = False\n",
    "\n",
    "if DO_VOLUME:\n",
    "\n",
    "    disrupt_type = 'V'\n",
    "    disrupt_steps = 50\n",
    "\n",
    "    resiliency_disruptions.make_disruption_scenarios(disrupt_type, disrupt_steps, scen_path)\n",
    "    resiliency_disruptions.disrupt_network(disrupt_type, disrupt_steps, scen_path, edges_remove)\n",
    "    results = resiliency_disruptions.run_o_steps(disrupt_type, disrupt_steps, scen_path, PYTHON, FTOT)\n",
    "    results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate disruption result report\n",
    "\n",
    "Run `compile_report.py`, which generates the `Disruption_Results.html` report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compile_report\n",
    "\n",
    "compile_report.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FTOTenv] *",
   "language": "python",
   "name": "conda-env-FTOTenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
